# üìö Documentaci√≥n T√©cnica ‚Äì Chispart CLI

<p align="center">
  <img src="./assets/logo.png" alt="Chispart CLI Logo" width="300">
</p>

Este documento describe el funcionamiento interno de **Chispart CLI**, la configuraci√≥n necesaria y c√≥mo interact√∫a con **Gemini API** y **ProjectAura (GPT)**.

---

## üî• Arquitectura de Comunicaci√≥n

```
Usuario ‚Üí Chispart CLI ‚Üí Gemini API ‚Üí Scripts / L√≥gica  
                                   ‚Ü≥ (cuando es necesario) ‚Üí ProjectAura ‚Üí Modelo GPT ‚Üí Respuesta enriquecida
```

üü£ **Gemini API** ‚Üí analiza y clasifica intenciones  
üîµ **ProjectAura (GPT)** ‚Üí resuelve tareas complejas  
üü¢ **Chispart CLI** ‚Üí orquesta y entrega resultados  
---

## ‚öôÔ∏è Componentes Principales

- **`chispart.js`** ‚Äì Punto de entrada; env√≠a consultas a Gemini API y decide si delegar a GPT.  
- **`projectaura.js`** ‚Äì Conector Node.js que se comunica con el endpoint GPT (OpenAI u otro compatible).  
- **`ask-projectaura.sh`** ‚Äì Wrapper que prepara las consultas para ProjectAura.  
- **`brain/intent-mapping.json`** ‚Äì Define intenciones, palabras clave y scripts a ejecutar.  
- **`actions/*.sh`** ‚Äì Scripts de automatizaci√≥n ejecutados seg√∫n la intenci√≥n detectada.

---

## üîê Configuraci√≥n de Claves API

Chispart CLI ahora soporta m√∫ltiples proveedores de LLM a trav√©s de ProjectAura. La configuraci√≥n se realiza mediante variables de entorno:

### Variables de Entorno Requeridas

- **`PROJECTAURA_API_KEY`** (Requerida): Clave de API del proveedor LLM
- **`PROJECTAURA_ENDPOINT`** (Opcional): Endpoint de la API (por defecto: OpenAI)
- **`PROJECTAURA_MODEL`** (Opcional): Modelo a utilizar (por defecto: "gpt-4o-mini")

### Configuraci√≥n para OpenAI (GPT)

```bash
export PROJECTAURA_API_KEY="sk-tu_clave_openai_aqui"
export PROJECTAURA_ENDPOINT="https://api.openai.com/v1/chat/completions"
export PROJECTAURA_MODEL="gpt-4o-mini"  # o gpt-4, gpt-3.5-turbo, etc.
```

### Configuraci√≥n para Mistral AI

```bash
export PROJECTAURA_API_KEY="tu_clave_mistral_aqui"
export PROJECTAURA_ENDPOINT="https://api.mistral.ai/v1/chat/completions"
export PROJECTAURA_MODEL="mistral-tiny"  # o mistral-small, mixtral-8x7b-instruct, etc.
```

### Configuraci√≥n para Otros Proveedores

Cualquier proveedor compatible con la API de OpenAI puede ser utilizado:

```bash
export PROJECTAURA_API_KEY="tu_clave_api"
export PROJECTAURA_ENDPOINT="https://tu-proveedor.com/v1/chat/completions"
export PROJECTAURA_MODEL="modelo_especifico"
```

---

## üö¶ Flujo de Ejecuci√≥n

1. El usuario escribe un comando natural:  
   ```bash
   chispart analiza logs del sistema
   ```
2. `chispart.js` env√≠a la entrada a **Gemini API**, que detecta la intenci√≥n "an√°lisis de logs".  
3. Si se requiere IA avanzada, llama a **ProjectAura**, que env√≠a la consulta a **GPT**.  
4. GPT devuelve un an√°lisis enriquecido que Chispart CLI presenta al usuario.

---

## üõ†Ô∏è Ejemplos de Uso Avanzado

### ‚úÖ Ejemplo 1: Consulta directa a LLM v√≠a ProjectAura
```bash
chispart consulta projectaura sobre optimizaci√≥n de rendimiento en React
chispart pregunta a aura sobre patrones de dise√±o
chispart consulta aura sobre mejores pr√°cticas de seguridad
```

### ‚úÖ Ejemplo 2: Cambio din√°mico de proveedor LLM
```bash
# Usar OpenAI para an√°lisis de c√≥digo
export PROJECTAURA_MODEL="gpt-4"
chispart consulta projectaura sobre refactorizaci√≥n de este c√≥digo

# Cambiar a Mistral para consultas generales
export PROJECTAURA_MODEL="mistral-small"
chispart pregunta a aura sobre arquitectura de software
```

### ‚úÖ Ejemplo 3: Manejo de errores mejorado
```bash
# Si hay un error en la ejecuci√≥n, ahora obtienes informaci√≥n detallada:
chispart prepara el entorno
# ‚ùå Error al ejecutar el script 'implement.sh':
#    Stderr: npm: command not found
#    Stdout (parcial): Iniciando configuraci√≥n del entorno...
```

---

## üß© Casos de Integraci√≥n

- **Desarrollo:** Asistencia con c√≥digo, refactorizaci√≥n y generaci√≥n de scripts usando diferentes LLMs seg√∫n la necesidad.
- **DevOps:** Despliegues automatizados con recomendaciones inteligentes de m√∫ltiples proveedores.
- **Data Analysis:** An√°lisis avanzado de logs, m√©tricas y sugerencias con flexibilidad de modelo.
- **Consultor√≠a:** Cambio din√°mico entre modelos especializados (GPT para c√≥digo, Mistral para an√°lisis general).

---

## üîß Mejoras T√©cnicas Implementadas

### Robustez del Sistema
- **Rutas absolutas:** Eliminaci√≥n de problemas de rutas relativas
- **Manejo de errores mejorado:** Informaci√≥n detallada de stderr y stdout
- **Validaci√≥n de respuestas:** Verificaci√≥n de estructura de respuesta de APIs

### Flexibilidad Multi-LLM
- **Configuraci√≥n din√°mica:** Cambio de proveedor sin modificar c√≥digo
- **Compatibilidad amplia:** Soporte para cualquier API compatible con OpenAI
- **Fallback inteligente:** Valores por defecto para configuraci√≥n m√≠nima

### Escalabilidad
- **Arquitectura modular:** F√°cil adici√≥n de nuevos proveedores
- **Variables de entorno:** Configuraci√≥n externa sin hardcoding
- **Logging mejorado:** Informaci√≥n de debugging para troubleshooting

---

## üìå Notas Finales

- **Flexibilidad Multi-LLM:** Chispart CLI ahora soporta OpenAI, Mistral y cualquier proveedor compatible.
- **Configuraci√≥n simple:** Cambio de proveedor mediante variables de entorno.
- **Robustez mejorada:** Manejo de errores detallado y rutas absolutas.
- **Dise√±o modular:** F√°cil extensi√≥n para nuevos proveedores y funcionalidades.

---

üöÄ **Con Chispart CLI obtienes una terminal con inteligencia h√≠brida y flexibilidad multi-LLM.**
